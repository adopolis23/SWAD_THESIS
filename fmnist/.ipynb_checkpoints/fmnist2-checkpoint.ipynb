{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "620d4880-257e-4e92-8367-6d52f6ca457c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T22:50:29.528577Z",
     "iopub.status.busy": "2024-01-18T22:50:29.528442Z",
     "iopub.status.idle": "2024-01-18T22:50:32.547679Z",
     "shell.execute_reply": "2024-01-18T22:50:32.547202Z",
     "shell.execute_reply.started": "2024-01-18T22:50:29.528561Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 17:50:29.686517: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from ModelGen import Generate_Model_2, ResNet18_2\n",
    "from SwadUtility import findStartAndEnd2\n",
    "from numpy.random import seed\n",
    "import random as ran\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "runs = 10\n",
    "\n",
    "\n",
    "NS = 3\n",
    "NE = 6\n",
    "r = 1.2\n",
    "\n",
    "swad_start_iter = 1\n",
    "rolling_window_size = 75\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f806b46-9482-476d-bd0f-04fe3881923b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T22:50:32.548715Z",
     "iopub.status.busy": "2024-01-18T22:50:32.548401Z",
     "iopub.status.idle": "2024-01-18T22:50:36.174910Z",
     "shell.execute_reply": "2024-01-18T22:50:36.174474Z",
     "shell.execute_reply.started": "2024-01-18T22:50:32.548695Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 17:50:32.555422: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-01-18 17:50:32.556273: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-01-18 17:50:32.665050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 17:50:32.667042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:c1:00.0 name: NVIDIA A40 computeCapability: 8.6\n",
      "coreClock: 1.74GHz coreCount: 84 deviceMemorySize: 44.40GiB deviceMemoryBandwidth: 648.29GiB/s\n",
      "2024-01-18 17:50:32.667059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-01-18 17:50:32.669941: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2024-01-18 17:50:32.669970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2024-01-18 17:50:32.672002: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-01-18 17:50:32.672830: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-01-18 17:50:32.674887: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-01-18 17:50:32.676277: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-01-18 17:50:32.679971: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-01-18 17:50:32.680104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 17:50:32.681920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 17:50:32.683586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-01-18 17:50:32.683901: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-18 17:50:32.684269: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-01-18 17:50:32.684359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 17:50:32.686135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:c1:00.0 name: NVIDIA A40 computeCapability: 8.6\n",
      "coreClock: 1.74GHz coreCount: 84 deviceMemorySize: 44.40GiB deviceMemoryBandwidth: 648.29GiB/s\n",
      "2024-01-18 17:50:32.686149: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-01-18 17:50:32.686162: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2024-01-18 17:50:32.686172: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2024-01-18 17:50:32.686181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-01-18 17:50:32.686191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-01-18 17:50:32.686200: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-01-18 17:50:32.686211: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-01-18 17:50:32.686220: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-01-18 17:50:32.686265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 17:50:32.688049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 17:50:32.689724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-01-18 17:50:32.689773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-01-18 17:50:36.124001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-01-18 17:50:36.124036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2024-01-18 17:50:36.124043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2024-01-18 17:50:36.124280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 17:50:36.126044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 17:50:36.127505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-18 17:50:36.128948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 42350 MB memory) -> physical GPU (device: 0, name: NVIDIA A40, pci bus id: 0000:c1:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'fashion_mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1795cd74-9644-4add-92e6-7a108167c082",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T22:50:36.175651Z",
     "iopub.status.busy": "2024-01-18T22:50:36.175508Z",
     "iopub.status.idle": "2024-01-18T22:50:36.430850Z",
     "shell.execute_reply": "2024-01-18T22:50:36.430375Z",
     "shell.execute_reply.started": "2024-01-18T22:50:36.175637Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.GaussianNoise(0.35),\n",
    "])\n",
    "\n",
    "ds_val = ds_train.take(3000) \n",
    "ds_train = ds_train.skip(3000)\n",
    "\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(batch_size)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_val = ds_val.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.cache()\n",
    "ds_val = ds_val.batch(batch_size)\n",
    "ds_val = ds_val.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test_ind = ds_test.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test_ind = ds_test_ind.batch(batch_size)\n",
    "ds_test_ind = ds_test_ind.cache()\n",
    "ds_test_ind = ds_test_ind.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test_ood = ds_test.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test_ood = ds_test_ood.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test_ood = ds_test_ood.batch(batch_size)\n",
    "ds_test_ood = ds_test_ood.cache()\n",
    "ds_test_ood = ds_test_ood.prefetch(tf.data.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77957c9d-3976-4128-8f58-089c17463cc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T22:50:36.431594Z",
     "iopub.status.busy": "2024-01-18T22:50:36.431451Z",
     "iopub.status.idle": "2024-01-18T22:50:36.438699Z",
     "shell.execute_reply": "2024-01-18T22:50:36.438212Z",
     "shell.execute_reply.started": "2024-01-18T22:50:36.431580Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [63528,30270,1186,47466,13938,27248,23050,32591,70485,44794,87752,67208,48357,41003,44268,55533,54862,59718,78523,69827,33651,12194,56602]\n",
    "\n",
    "\n",
    "def setSeed(x):\n",
    "    newSeed = int(x)\n",
    "    \n",
    "    ran.seed(newSeed)\n",
    "    seed(newSeed)\n",
    "    tf.random.set_seed(newSeed)\n",
    "\n",
    "    session_conf = tf.compat.v1.ConfigProto()\n",
    "\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = 'true'\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = 'true'\n",
    "\n",
    "def validate():\n",
    "  y_pred = model.predict(val_x, verbose=0)\n",
    "  bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "  val_loss = bce(val_y, y_pred).numpy()\n",
    "  return val_loss\n",
    "\n",
    "def validate2(val_ds):\n",
    "    return model.evaluate(val_ds, verbose=0)[0]\n",
    "\n",
    "def minVal(loss, curr_i, ns):\n",
    "    min_value = 999999999\n",
    "    \n",
    "    for i in range(ns):\n",
    "        if loss[curr_i - i] < min_value:\n",
    "            min_value = loss[curr_i - i]\n",
    "    \n",
    "    return min_value\n",
    "\n",
    "\n",
    "def avgLastR(loss, curr_i, ns, r):\n",
    "    curr_sum = 0\n",
    "    for i in range(ns):\n",
    "        curr_sum = curr_sum + loss[curr_i - i]\n",
    "    \n",
    "    curr_sum = float(curr_sum / ns) * r\n",
    "    \n",
    "    return curr_sum\n",
    "\n",
    "def avg_fn(averaged_model_parameter, model_parameter, num_averaged):\n",
    "                return averaged_model_parameter + (model_parameter - averaged_model_parameter) / (num_averaged + 1)\n",
    "    \n",
    "def avg_fn_a(averaged_model_parameter, model_parameter, num_averaged):\n",
    "                return np.add(averaged_model_parameter, np.divide(np.subtract(model_parameter, averaged_model_parameter), (num_averaged + 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6701bb92-7613-4b52-a5f4-1a61adac6d52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T22:50:36.439613Z",
     "iopub.status.busy": "2024-01-18T22:50:36.439405Z",
     "iopub.status.idle": "2024-01-18T22:50:36.449338Z",
     "shell.execute_reply": "2024-01-18T22:50:36.448958Z",
     "shell.execute_reply.started": "2024-01-18T22:50:36.439592Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class checkpoint(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.min_loss = 1000000\n",
    "        self.min_weight = None\n",
    "\n",
    "    def on_train_batch_end(self, epoch, logs=None):\n",
    "        val_loss = validate2(ds_val)\n",
    "\n",
    "        if val_loss < self.min_loss:\n",
    "            #print(\"\\nValidation loss improved saving weights\\n\")\n",
    "            self.min_loss = val_loss\n",
    "            self.min_weight = model.get_weights()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        print(\"\\nSetting new model weights.\\n\")\n",
    "        model.set_weights(self.min_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0bfbc26-0e48-4344-b8f2-fb5d62582f67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T22:50:36.451294Z",
     "iopub.status.busy": "2024-01-18T22:50:36.451083Z",
     "iopub.status.idle": "2024-01-18T22:50:36.471252Z",
     "shell.execute_reply": "2024-01-18T22:50:36.470864Z",
     "shell.execute_reply.started": "2024-01-18T22:50:36.451273Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#create callback for weight averaging\n",
    "class swad_callback_paper(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.ts = 0\n",
    "        self.te = (int(len(train_x)/batch_size)-1) * epochs\n",
    "        self.l = None\n",
    "        \n",
    "        self.averaged_model_param = None\n",
    "        self.num_averaged = 0\n",
    "        self.loss_tracker = []\n",
    "        \n",
    "        self.curr_iter = 0\n",
    "        \n",
    "    #function called at the end of every batch\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.loss_tracker.append(validate())\n",
    "        \n",
    "        if self.curr_iter >= 10:\n",
    "            if self.l == None:\n",
    "                if self.loss_tracker[self.curr_iter-NS+1] == minVal(self.loss_tracker, self.curr_iter, NS):\n",
    "                    self.ts = batch - NS + 1\n",
    "                    self.l = avgLastR(self.loss_tracker, self.curr_iter, NS, r)\n",
    "                    print(\"L set to {} ***\".format(self.l))\n",
    "                    print(\"TS set to {} ***\".format(self.ts))\n",
    "            if self.l != None and self.l < minVal(self.loss_tracker, self.curr_iter, NE):\n",
    "                te = self.curr_iter - NE\n",
    "                print(\"TE set to {} ***\".format(self.te))\n",
    "\n",
    "            #if the start iteration has been encountered\n",
    "            if self.l != None:\n",
    "                if self.averaged_model_param == None:\n",
    "                    self.averaged_model_param = model.get_weights()\n",
    "                else:\n",
    "                    self.averaged_model_param = avg_fn_a(self.averaged_model_param, model.get_weights(), self.num_averaged)\n",
    "                    self.num_averaged += 1\n",
    "\n",
    "            #early stopping condition\n",
    "            if self.curr_iter > self.te:\n",
    "                self.model.stop_training = True\n",
    "    \n",
    "        self.curr_iter += 1\n",
    "        \n",
    "    def on_train_end(self, logs=None):\n",
    "        print(\"TS is {}\".format(self.ts))\n",
    "        print(\"TE is {}\".format(self.te))\n",
    "        \n",
    "        df = pd.DataFrame(self.loss_tracker)\n",
    "        df.to_csv('loss.csv') \n",
    "        \n",
    "        print(\"Setting model weights...\")\n",
    "        model.set_weights(self.averaged_model_param)\n",
    "    \n",
    "weights = []\n",
    "new_weights = list()\n",
    "\n",
    "#create callback for weight averaging\n",
    "class swad_callback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        #list to track loss over training\n",
    "        self.iteration_tracker = 0\n",
    "        self.weights_saved = 0\n",
    "        self.min_loss = 100000000\n",
    "\n",
    "        self.rolling_last_weights = []\n",
    "        self.rolling_last_loss = []\n",
    "\n",
    "        self.curr_best_weight_hist = []\n",
    "        self.curr_best_loss_hist = []\n",
    "\n",
    "        self.curr_best_weight_right = []\n",
    "        self.curr_best_loss_right = []\n",
    "\n",
    "        self.best_loss_iteration = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    #function called at the end of every batch\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "\n",
    "        #finds the validation loss after this batch\n",
    "        #this is very slow and this is why this takes a while\n",
    "\n",
    "        if self.iteration_tracker >= swad_start_iter:\n",
    "            val_loss = validate(ds_val)\n",
    "\n",
    "            #keeping track of the rolling window\n",
    "            self.rolling_last_loss.append(val_loss)\n",
    "            while len(self.rolling_last_loss) > rolling_window_size:\n",
    "                self.rolling_last_loss.pop(0)\n",
    "\n",
    "            self.rolling_last_weights.append(model.get_weights())\n",
    "            while len(self.rolling_last_weights) > rolling_window_size:\n",
    "                self.rolling_last_weights.pop(0)\n",
    "\n",
    "            #new min loss found\n",
    "            if val_loss < self.min_loss:\n",
    "                self.min_loss = val_loss\n",
    "                self.curr_best_weight_hist = self.rolling_last_weights\n",
    "                self.curr_best_loss_hist = self.rolling_last_loss\n",
    "\n",
    "                self.curr_best_loss_right.clear()\n",
    "                self.curr_best_weight_right.clear()\n",
    "\n",
    "                self.best_loss_iteration = self.iteration_tracker\n",
    "            \n",
    "            #save the weights after the minimum\n",
    "            if len(self.curr_best_loss_right) < rolling_window_size:\n",
    "                self.curr_best_loss_right.append(val_loss)\n",
    "                self.curr_best_weight_right.append(model.get_weights())\n",
    "            \n",
    "            #debugging\n",
    "            #print(\"{} : {}\".format(len(self.curr_best_loss_hist), len(self.curr_best_loss_right)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self.iteration_tracker += 1\n",
    "\n",
    "\n",
    "    #function called at the end of training\n",
    "    #NOTE WEIGHT AVERAGING HAPPENS HERE\n",
    "    def on_train_end(self, logs=None):\n",
    "        print(\"\\nEnd of Training\")\n",
    "\n",
    "        print(\"Absolute best loss at: {}\".format(self.best_loss_iteration))\n",
    "        full_loss = self.curr_best_loss_hist + self.curr_best_loss_right\n",
    "        full_weights = self.curr_best_weight_hist + self.curr_best_weight_right\n",
    "\n",
    "        #finds the start and end iteration to average weights\n",
    "        ts, te, l = findStartAndEnd2(full_loss, NS, NE, r)\n",
    "        print(\"ts is {} and te is {}\".format(ts, te))\n",
    "\n",
    "        #optional plot the loss\n",
    "        #plt.plot(full_loss)\n",
    "        #lt.axvline(x=ts, color='r')\n",
    "        #plt.axvline(x=te, color='b')\n",
    "        #plt.show()\n",
    "\n",
    "        #optional save loss to csv\n",
    "        df = pd.DataFrame(full_loss)\n",
    "        df.to_csv('loss.csv') \n",
    "\n",
    "        print(\"\\nAveraging Weights.\")\n",
    "\n",
    "        for i, weight in enumerate(full_weights):\n",
    "            model.save_weights(\"Weights/weights_\" + str(i) + \".h5\")\n",
    "\n",
    "        new_weights = AverageWeights(model, ts, te, 200)\n",
    "\n",
    "        #set model weights to new average\n",
    "        if len(new_weights) > 0:\n",
    "            print(\"\\nSetting new model weights.\\n\")\n",
    "            model.set_weights(new_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945971a9-5f7f-444b-a184-b772fc71911e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T22:50:36.472190Z",
     "iopub.status.busy": "2024-01-18T22:50:36.471816Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Run Number: 0 *******\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method ResnetBlock.call of <ModelGen.ResnetBlock object at 0x15033c039ac0>> and will run it as-is.\n",
      "Cause: mangled names are not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method ResnetBlock.call of <ModelGen.ResnetBlock object at 0x15033c039ac0>> and will run it as-is.\n",
      "Cause: mangled names are not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method ResnetBlock.call of <ModelGen.ResnetBlock object at 0x15033c039ac0>> and will run it as-is.\n",
      "Cause: mangled names are not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 17:50:37.839437: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-01-18 17:50:37.860858: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1996370000 Hz\n",
      "2024-01-18 17:50:38.250704: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2024-01-18 17:50:39.408868: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(runs):\n",
    "    print(\"******* Run Number: {} *******\".format(i))\n",
    "    setSeed(seeds[i])\n",
    "    model = None\n",
    "    gc.collect()\n",
    "    \n",
    "    weights_folder = os.listdir(\"Weights\")\n",
    "    for file in weights_folder:\n",
    "        os.remove(\"Weights/\"+file)\n",
    "    \n",
    "    #model = Generate_Model_2(10, (28, 28, 1))\n",
    "\n",
    "    model = ResNet18_2(10)\n",
    "    model.build(input_shape = (None, 28, 28, 1))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        ds_train,\n",
    "        validation_data=ds_val,\n",
    "        epochs=epochs,\n",
    "        shuffle=True,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    scores = model.evaluate(ds_test_ind, verbose=1)\n",
    "    print('Test loss seen:', scores[0])\n",
    "    print('Test accuracy seen:', scores[1])\n",
    "\n",
    "    scores_unseen = model.evaluate(ds_test_ood, verbose=1)\n",
    "    print('Test loss unseen:', scores_unseen[0])\n",
    "    print('Test accuracy unseen:', scores_unseen[1])\n",
    "    \n",
    "    results.append([scores[1], scores_unseen[1]])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d11160-6acb-4232-b525-3466a95dc2b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.to_csv('multirun_results.csv')\n",
    "\n",
    "print(\"\\n\\n Final Results:\\n\")\n",
    "\n",
    "for i, x in enumerate(results):\n",
    "    print(\"\\nRun: {}, Loss-Seen: {}\".format(i, x[0]))\n",
    "    print(\"\\nRun: {}, Loss-unSeen: {}\".format(i, x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865263d8-d260-485f-9f05-342125a12ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tf_gpu]",
   "language": "python",
   "name": "conda-env-.conda-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
