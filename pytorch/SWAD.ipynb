{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6b6142a5-e896-4aee-8cce-f064362ac2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "daaac174-0672-400c-95b3-60e6812054a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c127a1f-72a6-4a6b-8a24-77e801c6b88a",
   "metadata": {},
   "source": [
    "## Load In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5ecca9d5-6724-4baf-90d9-a5e28ea203e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize(224),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor()\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3bf9b986-b273-438c-93a4-a5b8584eb5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\"data/train\", transform=transform) \n",
    "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "train_iter = iter(train_dl)\n",
    "\n",
    "val_dataset = datasets.ImageFolder(\"data/valid\", transform=transform) \n",
    "val_dl = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "val_iter = iter(val_dl)\n",
    "\n",
    "test_seen_dataset = datasets.ImageFolder(\"data/test-seen\", transform=transform) \n",
    "test_seen_dl = torch.utils.data.DataLoader(test_seen_dataset, batch_size=32, shuffle=True)\n",
    "test_seen_iter = iter(test_seen_dl)\n",
    "\n",
    "test_unseen_dataset = datasets.ImageFolder(\"data/test-unseen\", transform=transform) \n",
    "test_unseen_dl = torch.utils.data.DataLoader(test_unseen_dataset, batch_size=32, shuffle=True)\n",
    "test_unseen_iter = iter(test_unseen_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80375a1c-6d65-4776-91ec-496d0f1044da",
   "metadata": {},
   "source": [
    "## Helper Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4713ad84-f798-43cf-b63a-a4ed31e383c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b962acb3-985c-49a0-8ea0-836b4079f54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b0c96aef-9241-4959-ba74-31be5c8aa919",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accumulator:\n",
    "  def __init__(self, n):\n",
    "    self.data = [0.0] * n\n",
    "\n",
    "  def add(self, *args):\n",
    "    self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "  def __getitem__(self, i):\n",
    "    return self.data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ad7e5d06-6e6c-4776-a456-9a6a2a404705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    \"\"\"Compute the number of correct predictions.\"\"\"\n",
    "    #y_hat is batch_size by n_outputs and y is n_outputs\n",
    "    # y contains the index of the ground truth label\n",
    "\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1: #The output is a vector -- not just a scalar\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "        \n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867c8c9c-5279-4dce-9176-b3148f8497fc",
   "metadata": {},
   "source": [
    "## Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0f5652dd-98e2-472f-acb9-eb9ba79e11ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create network\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.fc1 = nn.Linear(6 * 110 * 110, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c370a23-0f6c-4e19-ae0f-9e5b9a27d0b7",
   "metadata": {},
   "source": [
    "## Training Loop Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "28e7a2c6-3e3c-4643-a828-dcee9c813f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(net, train_iter, loss, updater):\n",
    "  net.train()\n",
    "  net.to(device)\n",
    "\n",
    "  metric = Accumulator(3)\n",
    "\n",
    "  # for each batch in the training set\n",
    "  for inputs, labels in train_iter:\n",
    "    #inputs, labels = images.to(device), labels.to(device)\n",
    "    inputs = to_device(inputs, device)\n",
    "    labels = to_device(labels, device)\n",
    "      \n",
    "    if(inputs.shape[0] > labels.shape[0]):\n",
    "        inputs = inputs[:labels.shape[0],:,:,:]\n",
    "      \n",
    "    net_output = net(inputs)\n",
    "\n",
    "    l = loss(net_output, labels)\n",
    "    acc = accuracy(net_output, labels)\n",
    "\n",
    "    updater.zero_grad()\n",
    "\n",
    "    l.backward()\n",
    "\n",
    "    updater.step()\n",
    "\n",
    "    #adds loss for whole batch and batch size\n",
    "    metric.add(float(l) * len(labels), float(acc), labels.numel())\n",
    "\n",
    "  return metric[0] / metric[2], metric[1] / metric[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "92619a18-7d65-4a99-ae86-c8fdef05017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, epochs, dl, loss, trainer):\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "        history = train_one_epoch(net, iter(dl), loss, trainer)\n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        print(\"Epoch: {} -- Train Loss: {:.3f} Train Accuracy: {:.3f} Time: {:.3f} Sec\".format(epoch, history[0], history[1], epoch_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50e6634-c29b-4284-9316-d26fa0c9fe1d",
   "metadata": {},
   "source": [
    "## Interaction and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "632eaf35-ba01-4fc1-a6e7-c8e4bb2130c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 -- Train Loss: 0.998 Train Accuracy: 0.485 Time: 4.032 Sec\n",
      "Epoch: 1 -- Train Loss: 0.717 Train Accuracy: 0.569 Time: 3.823 Sec\n",
      "Epoch: 2 -- Train Loss: 0.778 Train Accuracy: 0.610 Time: 3.965 Sec\n",
      "Epoch: 3 -- Train Loss: 0.756 Train Accuracy: 0.568 Time: 3.978 Sec\n",
      "Epoch: 4 -- Train Loss: 0.720 Train Accuracy: 0.552 Time: 4.201 Sec\n",
      "Epoch: 5 -- Train Loss: 0.654 Train Accuracy: 0.631 Time: 4.141 Sec\n",
      "Epoch: 6 -- Train Loss: 0.665 Train Accuracy: 0.658 Time: 4.119 Sec\n",
      "Epoch: 7 -- Train Loss: 0.588 Train Accuracy: 0.718 Time: 4.003 Sec\n",
      "Epoch: 8 -- Train Loss: 0.583 Train Accuracy: 0.751 Time: 3.911 Sec\n",
      "Epoch: 9 -- Train Loss: 0.618 Train Accuracy: 0.687 Time: 4.052 Sec\n",
      "Epoch: 10 -- Train Loss: 0.517 Train Accuracy: 0.763 Time: 3.990 Sec\n",
      "Epoch: 11 -- Train Loss: 0.549 Train Accuracy: 0.728 Time: 4.003 Sec\n",
      "Epoch: 12 -- Train Loss: 0.551 Train Accuracy: 0.745 Time: 4.061 Sec\n",
      "Epoch: 13 -- Train Loss: 0.512 Train Accuracy: 0.753 Time: 3.941 Sec\n",
      "Epoch: 14 -- Train Loss: 0.554 Train Accuracy: 0.737 Time: 3.995 Sec\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "train(net, 15, train_dl, loss, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2564f964-fa67-4feb-a4ba-123b28f7a9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
